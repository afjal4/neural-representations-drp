# Neural Representations Directed Reading Program
Welcome to the Neural Representations DRP. Here are resources/ experiments relating to how computers represent abstract concepts. In particular, our focuses are on representational alignment using embedding geometry, and alignment metrics between representations.

## Resources

### Representational Alignment

### Alignment Metrics

## Exercises

### Tuesday 18th November 2025
This week, the aim is to familiarise yourself with pytorch. Train a classification model on the MNIST dataset, which is a (if not the most) classic ML task. We can then extend this to try and simulate non-idealities when training on neuromorphic hardware.

Try to implement 
MINST Tutorial: https://nextjournal.com/gkoehler/pytorch-mnist

Extention 1: a "Comittee Machine": https://www.nature.com/articles/s41467-020-18098-0

Another extention related to what we have been talking about in the Friday sessions it to try and implement the simple linear regression task on cross-lingual data. Perhaps the biggest hurdle will be in downloading the embedding model/data, so there is some artifical data in XXXX(not done yet...). That being said, it would be nice to recreate some results so those of you who are more confident in using PyTorch can begin to implement some of the results in the experiments folder. 

Clone/fork this repository, set up a venv and install requirements 

repo with link to download real word embedding data.
https://github.com/artetxem/vecmap
https://github.com/facebookresearch/MUSE
easier to read implementation: https://github.com/n8686025/word2vec-translation-matrix/blob/master/jp-en-translation.py
